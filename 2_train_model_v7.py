import pandas as pd
import numpy as np
import pandas_ta as ta
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import precision_score, recall_score, accuracy_score
from sklearn.model_selection import TimeSeriesSplit
import joblib
import os

# ==========================================
# 1. Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª (Ù†ÙØ³ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©)
# ==========================================
def feature_engineering_v7(df):
    data = df.copy()
    data['Returns'] = np.log(data['close'] / data['close'].shift(1))
    data['Range'] = (data['high'] - data['low']) / data['open']
    data['Vol_1H'] = data['Returns'].rolling(24).std()
    data['Vol_4H_Proxy'] = data['Returns'].rolling(24).std() 
    data['Vol_Ratio'] = data['Vol_1H'] / (data['Vol_4H_Proxy'] + 1e-9)
    
    data['Close_Loc'] = (data['close'] - data['low']) / (data['high'] - data['low'] + 1e-9)
    data['Volume_Flow'] = np.where(data['Close_Loc'] > 0.5, data['volume'], -data['volume'])
    data['CVD_Proxy'] = data['Volume_Flow'].rolling(12).sum()
    
    data['RSI'] = data.ta.rsi(length=14)
    data['MFI'] = data.ta.mfi(length=14)
    data['ADX'] = data.ta.adx(length=14)['ADX_14']
    
    change = data['close'].diff(10).abs()
    volatility = data['close'].diff().abs().rolling(10).sum()
    data['Efficiency_Ratio'] = change / (volatility + 1e-9)
    
    data['Funding_x_Vol'] = data['fundingRate'] * data['Vol_1H']
    data['Trend_4H'] = (data['close_4h'] > data['close_4h'].shift(1)).astype(int)
    
    data.dropna(inplace=True)
    return data

# ==========================================
# 2. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù (Triple Barrier)
# ==========================================
def labeling_triple_barrier(df, horizon=12, vol_mult=1.5):
    targets = []
    prices = df['close'].values
    atr = df.ta.atr(length=14).values
    
    for i in range(len(df) - horizon):
        curr = prices[i]
        cur_atr = atr[i] if not np.isnan(atr[i]) else curr * 0.01
        
        # Ø£Ù‡Ø¯Ø§Ù: Ø§Ù„Ø±Ø¨Ø­ Ø¶Ø¹Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹
        tp = curr + (cur_atr * vol_mult * 1.5)
        sl = curr - (cur_atr * vol_mult * 0.8)
        
        outcome = 0
        for j in range(1, horizon + 1):
            if i+j >= len(df): break
            high = df.iloc[i+j]['high']
            low = df.iloc[i+j]['low']
            
            if low <= sl:
                outcome = 0
                break
            if high >= tp:
                outcome = 1
                break
        targets.append(outcome)
    return targets

# ==========================================
# 3. Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ù…Ø¹Ø§ÙŠØ±Ø© (The Sniper Calibration)
# ==========================================
def train_brain_v7():
    print("ğŸ§  (V7.2 Sniper Calibration) Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ù…Ø¹Ø§ÙŠØ±Ø© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©...")
    
    if not os.path.exists('data/btc_data_v7.csv'):
        print("âŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø©!")
        return

    df = pd.read_csv('data/btc_data_v7.csv')
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    print("ğŸ› ï¸ Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª...")
    df = feature_engineering_v7(df)
    
    print("ğŸ¯ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù...")
    targets = labeling_triple_barrier(df)
    df = df.iloc[:len(targets)]
    df['Target'] = targets
    
    features = [
        'RSI', 'MFI', 'ADX', 'Efficiency_Ratio', 
        'Vol_Ratio', 'CVD_Proxy', 'fundingRate', 
        'Funding_x_Vol', 'Trend_4H', 'Range'
    ]
    
    X = df[features]
    y = df['Target']
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¢Ø®Ø± 20% Ø§Ø®ØªØ¨Ø§Ø±)
    split = int(len(X) * 0.80)
    X_train, X_test = X.iloc[:split], X.iloc[split:]
    y_train, y_test = y.iloc[:split], y.iloc[split:]
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆØ²Ù† (Ù…Ø®ÙÙ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø©)
    count_0 = (y_train == 0).sum()
    count_1 = (y_train == 1).sum()
    # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¬Ø°Ø± Ø§Ù„ØªØ±Ø¨ÙŠØ¹ÙŠ Ù„ØªØ®ÙÙŠÙ Ø­Ø¯Ø© Ø§Ù„Ù…ÙˆØ§Ø²Ù†Ø©ØŒ Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¯Ù‚Ø©
    scale_weight = np.sqrt(count_0 / count_1) 
    print(f"âš–ï¸ Ù…ÙˆØ§Ø²Ù†Ø© Ø°ÙƒÙŠØ©: {count_0} vs {count_1} | Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ù…Ø¹Ø¯Ù„ = {scale_weight:.2f}")

    # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    clf1 = XGBClassifier(
        n_estimators=800, learning_rate=0.01, max_depth=5, 
        scale_pos_weight=scale_weight, 
        subsample=0.7, colsample_bytree=0.7, random_state=42, n_jobs=-1
    )
    
    clf2 = CatBoostClassifier(
        iterations=800, learning_rate=0.01, depth=6, 
        auto_class_weights='SqrtBalanced', # Ù…ÙˆØ§Ø²Ù†Ø© Ø£Ø®Ù
        verbose=False, allow_writing_files=False, random_state=42
    )
    
    clf3 = LGBMClassifier(
        n_estimators=800, learning_rate=0.01, max_depth=5, 
        class_weight='balanced',
        random_state=42, n_jobs=-1, verbose=-1
    )
    
    ensemble = VotingClassifier(
        estimators=[('xgb', clf1), ('cat', clf2), ('lgbm', clf3)],
        voting='soft'
    )
    
    print("ğŸ‹ï¸â€â™‚ï¸ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©...")
    ensemble.fit(X_train, y_train)
    
    # ---------------------------------------------------------
    # ğŸ”¬ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ© (Threshold Optimization)
    # ---------------------------------------------------------
    print("\nğŸ”­ ÙØ­Øµ Ø§Ù„Ù…Ù†Ø¸Ø§Ø± (Calibration Analysis):")
    print("-" * 50)
    print(f"{'Threshold':<10} | {'Precision':<10} | {'Win Rate':<10} | {'Trades':<10}")
    print("-" * 50)
    
    probs = ensemble.predict_proba(X_test)[:, 1]
    
    best_thresh = 0.5
    best_prec = 0.0
    
    # Ù†Ø¬Ø±Ø¨ Ø¹ØªØ¨Ø§Øª Ù…Ù† 50% Ø¥Ù„Ù‰ 95%
    for t in [0.5, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]:
        preds = (probs >= t).astype(int)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        if preds.sum() > 0:
            prec = precision_score(y_test, preds, zero_division=0)
            trades = preds.sum()
            
            print(f"{t:<10} | {prec:.2%}    | {prec:.2%}    | {trades}")
            
            # Ù†Ø±ÙŠØ¯ Ø¯Ù‚Ø© ÙÙˆÙ‚ 50% Ù…Ø¹ Ø¹Ø¯Ø¯ ØµÙÙ‚Ø§Øª Ù…Ø¹Ù‚ÙˆÙ„ (Ø£ÙƒØ«Ø± Ù…Ù† 50 ØµÙÙ‚Ø© ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±)
            if prec > best_prec and trades > 20:
                best_prec = prec
                best_thresh = t
        else:
            print(f"{t:<10} | 0.00%      | 0.00%      | 0")

    print("-" * 50)
    print(f"ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ©: Ø§Ø³ØªØ®Ø¯Ù… Threshold = {best_thresh} ÙÙŠ Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¯Ù‚Ø© {best_prec:.1%}")
    
    # Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    print("\nğŸš€ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Full Deployment)...")
    ensemble.fit(X, y)
    
    if not os.path.exists('models'): os.makedirs('models')
    joblib.dump(ensemble, 'models/btc_v7_ensemble.pkl')
    print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù‚Ù†Ø§Øµ Ø§Ù„Ø¬Ø¯ÙŠØ¯.")

if __name__ == "__main__":
    train_brain_v7()